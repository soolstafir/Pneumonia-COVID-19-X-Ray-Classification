{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting COVID-19 & Viral Pneumonia in X-Ray Images\n",
    "\n",
    "Dataset from: https://www.kaggle.com/tawsifurrahman/covid19-radiography-database?\n",
    "\n",
    "\n",
    "Also using COVID-19 X-Rays from https://www.kaggle.com/nabeelsajid917/covid-19-x-ray-10000-images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\radiu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\radiu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\radiu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\radiu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\radiu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\radiu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\radiu\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\radiu\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\radiu\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\radiu\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\radiu\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\radiu\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from random import shuffle\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:\\\\Users\\\\faiza\\\\COVID-19 Deep Learning\\\\'\n",
    "path = 'E:\\\\Downloads\\\\dataset\\\\COVID-19-Database'\n",
    "\n",
    "IMAGE_WIDTH = 200\n",
    "IMAGE_HEIGHT = 200\n",
    "\n",
    "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'E:\\\\Downloads\\\\dataset\\\\COVID-19-Databasetrain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-81c0edde5fb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdirectories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'E:\\\\Downloads\\\\dataset\\\\COVID-19-Databasetrain'"
     ]
    }
   ],
   "source": [
    "directories = ['train']\n",
    "categories = []\n",
    "    \n",
    "files = os.listdir(path + directories[0])\n",
    "\n",
    "for img in files:\n",
    "\n",
    "    fileName = img.split('.')[0]\n",
    "    \n",
    "    if 'NORMAL' in fileName: categories.append(0)\n",
    "    elif 'COVID-19' in fileName: categories.append(1)\n",
    "    else: categories.append(2)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': files,\n",
    "    'category': categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "0 Represents Normal \n",
    "1 Represents COVID-19\n",
    "2 Represents Viral Pneumonia \n",
    "'''\n",
    "df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.choice(os.listdir(path + directories[0]))\n",
    "image = load_img(path + '\\\\train\\\\' + sample)\n",
    "\n",
    "print(sample)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "\n",
    "1. **Input Layer**: This represents our input image data. It will reshape the image into a single dimensional array. For example, if your image is 64x64, it will convert to (4096,1) array (64x64 = 4096).\n",
    "\n",
    "\n",
    "2. **Conv Layer**: This layer will extract features from image.\n",
    "\n",
    "\n",
    "3. **Pooling Layer**: This layer will reduce the spatial volume of input image after convolution.\n",
    "\n",
    "\n",
    "4. **Fully Connected Layer**: This will connect the network from a layer to another layer\n",
    "\n",
    "\n",
    "5. **Output Layer**: This is the predicted values layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax', name='predictions')) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "## Early Stop\n",
    "\n",
    "To prevent overfitting, we will stop the learning after 10 epochs and if the val_loss value has not decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Reduction\n",
    "\n",
    "We will reduce the learning rate when then accuracy does not increase for 2 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy', \n",
    "                                            patience = 2, \n",
    "                                            verbose = 1, \n",
    "                                            factor = 0.5, \n",
    "                                            min_lr = 0.00001)\n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0: 'Normal', 1: 'COVID-19', 2: 'Viral Pneumonia'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator (\n",
    "    \n",
    "    rotation_range = 15,\n",
    "    rescale = 1./255,\n",
    "    \n",
    "    shear_range = 0.1,\n",
    "    zoom_range = 0.2,\n",
    "    \n",
    "    horizontal_flip = True,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe (\n",
    "    \n",
    "    train_df, \n",
    "    path + '\\\\train', \n",
    "    x_col = 'filename',\n",
    "    y_col = 'category',\n",
    "    target_size = IMAGE_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe (\n",
    "    \n",
    "    validate_df, \n",
    "    path + '\\\\train', \n",
    "    x_col ='filename',\n",
    "    y_col = 'category',\n",
    "    target_size = IMAGE_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = train_df.sample(n=1).reset_index(drop=True)\n",
    "\n",
    "example_generator = train_datagen.flow_from_dataframe (\n",
    "    \n",
    "    example_df, \n",
    "    path + '\\\\train', \n",
    "    x_col = 'filename',\n",
    "    y_col = 'category',\n",
    "    target_size = IMAGE_SIZE,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_df)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i in range(0, 15):\n",
    "    \n",
    "    plt.subplot(5, 3, i+1)\n",
    "    \n",
    "    for X_batch, Y_batch in example_generator:\n",
    "        image = X_batch[0]\n",
    "        plt.imshow(image)\n",
    "        break\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "\n",
    "history = model.fit_generator (\n",
    "    \n",
    "    train_generator, \n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = total_validate//batch_size,\n",
    "    steps_per_epoch = total_train//batch_size,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"COVID-Model-{}-{}-{}-{}.h5\".format(IMAGE_WIDTH, 3, batch_size, epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Training Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "numEpochs = range(1,  epochs + 1)\n",
    "plt.plot(numEpochs, accuracy, 'g', label='Training Accuracy')\n",
    "plt.plot(numEpochs, val_accuracy, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "numEpochs = range(1,  epochs + 1)\n",
    "plt.plot(numEpochs, loss, 'g', label='Training Loss')\n",
    "plt.plot(numEpochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(path + 'test')\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "\n",
    "nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Testing Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(rescale = 1./255)\n",
    "test_generator = test_gen.flow_from_dataframe(\n",
    "    \n",
    "    test_df, \n",
    "    path + '\\\\test', \n",
    "    x_col = 'filename',\n",
    "    y_col = None,\n",
    "    class_mode = None,\n",
    "    target_size = IMAGE_SIZE,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_generator(test_generator, steps = np.ceil(nb_samples/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick the category that has the highest probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category'] = np.argmax(predict, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "test_df['category'] = test_df['category'].replace(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category'] = test_df['category'].replace({'Normal': 0, 'COVID-19': 1, 'Viral Pneumonia': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted result with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = test_df.head(18)\n",
    "sample_test.head()\n",
    "\n",
    "plt.figure(figsize=(12, 24))\n",
    "\n",
    "for index, row in sample_test.iterrows():\n",
    "    \n",
    "    filename = row['filename']\n",
    "    category = row['category']\n",
    "    \n",
    "    img = load_img(path + 'test\\\\' + filename, target_size=IMAGE_SIZE)\n",
    "    \n",
    "    plt.subplot(6, 3, index+1)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(filename + ' Pred: (' + \"{}\".format(category) + ')' )\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = test_df\n",
    "correctPredictions = 0\n",
    "\n",
    "correctNormalPred = 0\n",
    "correctCovidPred = 0\n",
    "correctPneuPred = 0\n",
    "\n",
    "totalNormalPred = 0\n",
    "totalCovidPred = 0\n",
    "totalPneuPred = 0\n",
    "\n",
    "for index, row in sample_test.iterrows():\n",
    "    \n",
    "    filename = row['filename']\n",
    "    prediction = row['category']\n",
    "    \n",
    "    img = load_img(path + 'test\\\\' + filename, target_size=IMAGE_SIZE)\n",
    "    \n",
    "    if 'NORMAL' in filename:\n",
    "        \n",
    "        if prediction == 0:\n",
    "            correctPredictions += 1\n",
    "            correctNormalPred += 1\n",
    "            \n",
    "        totalNormalPred += 1\n",
    "    \n",
    "    if 'COVID-19' in filename:\n",
    "        \n",
    "        if prediction == 1: \n",
    "            correctPredictions += 1\n",
    "            correctCovidPred += 1\n",
    "            \n",
    "        totalCovidPred += 1\n",
    "    \n",
    "    if 'Viral Pneumonia' in filename:\n",
    "        \n",
    "        if prediction == 2: \n",
    "            correctPredictions += 1\n",
    "            correctPneuPred += 1\n",
    "            \n",
    "        totalPneuPred += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model Accuracy:', \"{:.2%}\".format(correctPredictions / test_df.shape[0]))\n",
    "print('Correct Predictions:', correctPredictions, 'Total Predictions:', test_df.shape[0])\n",
    "\n",
    "print('\\nNormal Predictions:', correctNormalPred, 'Accuracy', \"{:.2%}\".format(correctNormalPred /  totalNormalPred))\n",
    "print('COVID-19 Predictions:', correctCovidPred, 'Accuracy', \"{:.2%}\".format(correctCovidPred /  totalCovidPred))\n",
    "print('Viral Pneumonia Predictions:', correctPneuPred, 'Accuracy', \"{:.2%}\".format(correctPneuPred / totalPneuPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "pred = []\n",
    "\n",
    "for row in test_df.iterrows():\n",
    "    \n",
    "    filename = row[1][0]\n",
    "    \n",
    "    if 'NORMAL' in filename: actual.append(0)\n",
    "    if 'COVID-19' in filename: actual.append(1)\n",
    "    if 'Viral Pneumonia' in filename: actual.append(2)\n",
    "        \n",
    "    pred.append(row[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(actual, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing CNN Model\n",
    "\n",
    "It is crucial that we visualize what our model is doing â€“ and on what basis it is making its predictions. Saliency maps form a visualization of the pixels in the image that contribute the most to predictions by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.load_weights('COVID-Model-200-3-5-25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.visualization import visualize_saliency\n",
    "from vis.utils import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndimage\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the to be visualized layer above\n",
    "layer_index = utils.find_layer_idx(model, 'predictions')\n",
    "\n",
    "# Swap softmax with linear\n",
    "model.layers[layer_index].activation = activations.linear\n",
    "model = utils.apply_modifications(model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageAPath = '/Users/faizanahmed/COVID-19 Deep Learning/train/COVID-19 (52).png'\n",
    "imageA = cv2.imread(imageAPath)\n",
    "imageA = cv2.resize(imageA, (200, 200)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization = visualize_saliency(model, layer_index, seed_input=imageA, filter_indices=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Areas of yellow gradient indicate high importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize = (15, 10))\n",
    "axes[0].imshow(imageA) \n",
    "axes[0].set_title('COVID-19')\n",
    "axes[1].imshow(visualization)\n",
    "axes[1].set_title('Saliency Map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaySaliencyMap(model, layer, category, image):\n",
    "    \n",
    "    visualization = visualize_saliency(model, layer, filter_indices=category, seed_input=image, backprop_modifier=None, grad_modifier=\"absolute\")\n",
    "\n",
    "    gaus = ndimage.gaussian_filter(visualization, sigma=5)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize = (15, 10))\n",
    "    axes[0].imshow(image) \n",
    "    axes[0].set_title(filename)\n",
    "    axes[1].imshow(image)\n",
    "    axes[1].imshow(gaus,alpha=.7)\n",
    "    axes[1].set_title('Saliency Map')\n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Gaussian Filter \n",
    "\n",
    "The areas that are highlighted are deemed as important to the model and contribute most to the classification of the image. They are the features that had the greatest influence in the prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saliency Maps for COVID-19 X-Rays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, filename in enumerate(df.iloc[35 : 50,0]):\n",
    "    \n",
    "    image = cv2.imread(path + 'train/' + filename)\n",
    "    image = cv2.resize(image, (200, 200)) \n",
    "    \n",
    "    displaySaliencyMap(model, layer_index, 1, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency Maps for Viral Pneumonia X-Rays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, filename in enumerate(df.iloc[600 : 615,0]):\n",
    "    \n",
    "    image = cv2.imread(path + 'train/' + filename)\n",
    "    image = cv2.resize(image, (200, 200)) \n",
    "    \n",
    "    displaySaliencyMap(model, layer_index, 2, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency Maps for Normal X-Rays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, filename in enumerate(df.iloc[300 : 315,0]):\n",
    "    \n",
    "    image = cv2.imread(path + 'train/' + filename)\n",
    "    image = cv2.resize(image, (200, 200)) \n",
    "    \n",
    "    displaySaliencyMap(model, layer_index, 0, image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
